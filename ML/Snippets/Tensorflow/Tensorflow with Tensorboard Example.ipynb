{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.pieriandata.com\"><img src=\"../Pierian_Data_Logo.PNG\"></a>\n",
    "<strong><center>Copyright by Pierian Data Inc.</center></strong> \n",
    "<strong><center>Created by Jose Marcial Portilla.</center></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras API Project Exercise\n",
    "\n",
    "## The Data\n",
    "\n",
    "We will be using a subset of the LendingClub DataSet obtained from Kaggle: https://www.kaggle.com/wordsforthewise/lending-club\n",
    "\n",
    "## NOTE: Do not download the full zip from the link! We provide a special version of this file that has some extra feature engineering for you to do. You won't be able to follow along with the original file!\n",
    "\n",
    "LendingClub is a US peer-to-peer lending company, headquartered in San Francisco, California.[3] It was the first peer-to-peer lender to register its offerings as securities with the Securities and Exchange Commission (SEC), and to offer loan trading on a secondary market. LendingClub is the world's largest peer-to-peer lending platform.\n",
    "\n",
    "### Our Goal\n",
    "\n",
    "Given historical data on loans given out with information on whether or not the borrower defaulted (charge-off), can we build a model thatcan predict wether or nor a borrower will pay back their loan? This way in the future when we get a new potential customer we can assess whether or not they are likely to pay back the loan. Keep in mind classification metrics when evaluating the performance of your model!\n",
    "\n",
    "The \"loan_status\" column contains our label.\n",
    "\n",
    "### Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "-----\n",
    "There are many LendingClub data sets on Kaggle. Here is the information on this particular data set:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>LoanStatNew</th>\n",
    "      <th>Description</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>loan_amnt</td>\n",
    "      <td>The listed amount of the loan applied for by the borrower. If at some point in time, the credit department reduces the loan amount, then it will be reflected in this value.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>term</td>\n",
    "      <td>The number of payments on the loan. Values are in months and can be either 36 or 60.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>int_rate</td>\n",
    "      <td>Interest Rate on the loan</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>installment</td>\n",
    "      <td>The monthly payment owed by the borrower if the loan originates.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>grade</td>\n",
    "      <td>LC assigned loan grade</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>5</th>\n",
    "      <td>sub_grade</td>\n",
    "      <td>LC assigned loan subgrade</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>6</th>\n",
    "      <td>emp_title</td>\n",
    "      <td>The job title supplied by the Borrower when applying for the loan.*</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>7</th>\n",
    "      <td>emp_length</td>\n",
    "      <td>Employment length in years. Possible values are between 0 and 10 where 0 means less than one year and 10 means ten or more years.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>8</th>\n",
    "      <td>home_ownership</td>\n",
    "      <td>The home ownership status provided by the borrower during registration or obtained from the credit report. Our values are: RENT, OWN, MORTGAGE, OTHER</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>9</th>\n",
    "      <td>annual_inc</td>\n",
    "      <td>The self-reported annual income provided by the borrower during registration.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>10</th>\n",
    "      <td>verification_status</td>\n",
    "      <td>Indicates if income was verified by LC, not verified, or if the income source was verified</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>11</th>\n",
    "      <td>issue_d</td>\n",
    "      <td>The month which the loan was funded</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>12</th>\n",
    "      <td>loan_status</td>\n",
    "      <td>Current status of the loan</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>13</th>\n",
    "      <td>purpose</td>\n",
    "      <td>A category provided by the borrower for the loan request.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>14</th>\n",
    "      <td>title</td>\n",
    "      <td>The loan title provided by the borrower</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>15</th>\n",
    "      <td>zip_code</td>\n",
    "      <td>The first 3 numbers of the zip code provided by the borrower in the loan application.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>16</th>\n",
    "      <td>addr_state</td>\n",
    "      <td>The state provided by the borrower in the loan application</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>17</th>\n",
    "      <td>dti</td>\n",
    "      <td>A ratio calculated using the borrower’s total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the borrower’s self-reported monthly income.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>18</th>\n",
    "      <td>earliest_cr_line</td>\n",
    "      <td>The month the borrower's earliest reported credit line was opened</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>19</th>\n",
    "      <td>open_acc</td>\n",
    "      <td>The number of open credit lines in the borrower's credit file.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>20</th>\n",
    "      <td>pub_rec</td>\n",
    "      <td>Number of derogatory public records</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>21</th>\n",
    "      <td>revol_bal</td>\n",
    "      <td>Total credit revolving balance</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>22</th>\n",
    "      <td>revol_util</td>\n",
    "      <td>Revolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>23</th>\n",
    "      <td>total_acc</td>\n",
    "      <td>The total number of credit lines currently in the borrower's credit file</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>24</th>\n",
    "      <td>initial_list_status</td>\n",
    "      <td>The initial listing status of the loan. Possible values are – W, F</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>25</th>\n",
    "      <td>application_type</td>\n",
    "      <td>Indicates whether the loan is an individual application or a joint application with two co-borrowers</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>26</th>\n",
    "      <td>mort_acc</td>\n",
    "      <td>Number of mortgage accounts.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>27</th>\n",
    "      <td>pub_rec_bankruptcies</td>\n",
    "      <td>Number of public record bankruptcies</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "---\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starter Code\n",
    "\n",
    "#### Note: We also provide feature information on the data as a .csv file for easy lookup throughout the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Epoch 1/600\n",
      "9881/9881 [==============================] - 9s 894us/step - loss: 0.2888 - val_loss: 0.2647\n",
      "Epoch 2/600\n",
      "9881/9881 [==============================] - 12s 1ms/step - loss: 0.2686 - val_loss: 0.2633\n",
      "Epoch 3/600\n",
      "9881/9881 [==============================] - 17s 2ms/step - loss: 0.2676 - val_loss: 0.2632\n",
      "Epoch 4/600\n",
      "9881/9881 [==============================] - 17s 2ms/step - loss: 0.2672 - val_loss: 0.2631\n",
      "Epoch 5/600\n",
      "9881/9881 [==============================] - 17s 2ms/step - loss: 0.2669 - val_loss: 0.2625\n",
      "Epoch 6/600\n",
      "9881/9881 [==============================] - 17s 2ms/step - loss: 0.2667 - val_loss: 0.2632\n",
      "Epoch 7/600\n",
      "9881/9881 [==============================] - 17s 2ms/step - loss: 0.2663 - val_loss: 0.2622\n",
      "Epoch 8/600\n",
      "9881/9881 [==============================] - 17s 2ms/step - loss: 0.2661 - val_loss: 0.2636\n",
      "Epoch 9/600\n",
      "9881/9881 [==============================] - 17s 2ms/step - loss: 0.2658 - val_loss: 0.2626\n",
      "Epoch 10/600\n",
      "9881/9881 [==============================] - 18s 2ms/step - loss: 0.2660 - val_loss: 0.2625\n",
      "Epoch 11/600\n",
      "9881/9881 [==============================] - 16s 2ms/step - loss: 0.2656 - val_loss: 0.2621\n",
      "Epoch 12/600\n",
      "9881/9881 [==============================] - 9s 889us/step - loss: 0.2655 - val_loss: 0.2634\n",
      "Epoch 13/600\n",
      "9881/9881 [==============================] - 9s 930us/step - loss: 0.2652 - val_loss: 0.2624\n",
      "Epoch 14/600\n",
      "9881/9881 [==============================] - 10s 964us/step - loss: 0.2653 - val_loss: 0.2615\n",
      "Epoch 15/600\n",
      "9881/9881 [==============================] - 12s 1ms/step - loss: 0.2649 - val_loss: 0.2618\n",
      "Epoch 16/600\n",
      "9881/9881 [==============================] - 16s 2ms/step - loss: 0.2650 - val_loss: 0.2627\n",
      "Epoch 17/600\n",
      "9881/9881 [==============================] - 17s 2ms/step - loss: 0.2649 - val_loss: 0.2623\n",
      "Epoch 18/600\n",
      "9881/9881 [==============================] - 16s 2ms/step - loss: 0.2649 - val_loss: 0.2624\n",
      "Epoch 19/600\n",
      "9881/9881 [==============================] - 16s 2ms/step - loss: 0.2651 - val_loss: 0.2631\n",
      "Epoch 20/600\n",
      "9881/9881 [==============================] - 16s 2ms/step - loss: 0.2645 - val_loss: 0.2635\n",
      "Epoch 21/600\n",
      "9881/9881 [==============================] - 16s 2ms/step - loss: 0.2641 - val_loss: 0.2623\n",
      "Epoch 22/600\n",
      "9881/9881 [==============================] - 16s 2ms/step - loss: 0.2642 - val_loss: 0.2628\n",
      "Epoch 23/600\n",
      "9881/9881 [==============================] - 16s 2ms/step - loss: 0.2647 - val_loss: 0.2625\n",
      "Epoch 24/600\n",
      "9881/9881 [==============================] - 16s 2ms/step - loss: 0.2645 - val_loss: 0.2617\n",
      "Epoch 25/600\n",
      "9881/9881 [==============================] - 16s 2ms/step - loss: 0.2640 - val_loss: 0.2619\n",
      "Epoch 26/600\n",
      "9881/9881 [==============================] - 16s 2ms/step - loss: 0.2640 - val_loss: 0.2620\n",
      "Epoch 27/600\n",
      "9881/9881 [==============================] - 16s 2ms/step - loss: 0.2642 - val_loss: 0.2627\n",
      "Epoch 28/600\n",
      "9881/9881 [==============================] - 16s 2ms/step - loss: 0.2640 - val_loss: 0.2625\n",
      "Epoch 29/600\n",
      "9881/9881 [==============================] - 16s 2ms/step - loss: 0.2638 - val_loss: 0.2637\n",
      "Epoch 30/600\n",
      "9881/9881 [==============================] - 16s 2ms/step - loss: 0.2642 - val_loss: 0.2618\n",
      "Epoch 31/600\n",
      "9881/9881 [==============================] - 16s 2ms/step - loss: 0.2639 - val_loss: 0.2625\n",
      "Epoch 32/600\n",
      "9881/9881 [==============================] - 16s 2ms/step - loss: 0.2638 - val_loss: 0.2627\n",
      "Epoch 33/600\n",
      "9881/9881 [==============================] - 16s 2ms/step - loss: 0.2633 - val_loss: 0.2616\n",
      "Epoch 34/600\n",
      "9881/9881 [==============================] - 17s 2ms/step - loss: 0.2631 - val_loss: 0.2630\n",
      "Epoch 34: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20e13e6bca0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def f(mort_acc, total_acc):\n",
    "    if pd.isna(mort_acc):\n",
    "        return mean_values[total_acc]\n",
    "    else:\n",
    "        return mort_acc\n",
    "\n",
    "\n",
    "df = pd.read_csv('../DATA/lending_club_loan_two.csv')\n",
    "\n",
    "map_values = {'Fully Paid': 1, 'Charged Off': 0}\n",
    "df['loan_repaid'] = df['loan_status'].map(map_values)\n",
    "\n",
    "map_values = ['NONE', 'ANY']\n",
    "df['home_ownership'] = df['home_ownership'].replace(map_values, 'OTHER')\n",
    "\n",
    "df.drop(['emp_title', 'emp_length', 'title', 'grade', 'issue_d', 'loan_status'], axis=1, inplace=True)\n",
    "\n",
    "mean_values = df.groupby('total_acc').mean(numeric_only=True)['mort_acc']\n",
    "df['mort_acc'] = df.apply(lambda x: f(x.mort_acc, x.total_acc), axis=1)\n",
    "df['term'] = df.term.str.replace(r'[^0-9]', '', regex=True).astype('int')\n",
    "df['zip_code'] = df['address'].str[-5:]\n",
    "df['earliest_cr_line'] = df.earliest_cr_line.str.replace(r'[^0-9]', '', regex=True).astype('int')\n",
    "\n",
    "df.drop('address', axis=1, inplace=True)\n",
    "\n",
    "df.dropna(how='any', subset=['revol_util', 'pub_rec_bankruptcies'], inplace=True)\n",
    "\n",
    "dummies = pd.get_dummies(df[['zip_code', 'home_ownership', 'sub_grade', 'verification_status', 'application_type','initial_list_status','purpose']], drop_first=True)\n",
    "df = pd.concat([df.drop(['zip_code', 'home_ownership', 'sub_grade', 'verification_status', 'application_type','initial_list_status','purpose'], axis=1), dummies], axis=1)\n",
    "\n",
    "X = df.drop('loan_repaid', axis=1)\n",
    "y = df.loan_repaid\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# add the layers of neurons\n",
    "# add the layers of neurons\n",
    "model.add(Dense(78, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(39, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(19, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "# BINARY CLASIFICATION\n",
    "# hence the use of activation='sigmoid'\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# will stop the model overfitting by monitoring validation loss\n",
    "# mode='min' because you want to minimise the validation loss (stop at the lowest point on the val_loss graph above)\n",
    "# patience Number of epochs with no improvement after which training will be stopped.\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "model.fit(x=X_train, y=y_train, epochs=600, validation_data=(X_test, y_test), callbacks=[early_stop], batch_size=32)\n",
    "\n",
    "model.save('code_along.h5')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "!rm -rf ./logs/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Epoch 1/600\n",
      "618/618 [==============================] - 3s 4ms/step - loss: 0.3708 - val_loss: 0.3170\n",
      "Epoch 2/600\n",
      "618/618 [==============================] - 2s 3ms/step - loss: 0.3233 - val_loss: 0.3052\n",
      "Epoch 3/600\n",
      "618/618 [==============================] - 2s 3ms/step - loss: 0.3142 - val_loss: 0.2958\n",
      "Epoch 4/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.3098 - val_loss: 0.2902\n",
      "Epoch 5/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.3025 - val_loss: 0.2631\n",
      "Epoch 6/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2851 - val_loss: 0.2621\n",
      "Epoch 7/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2810 - val_loss: 0.2615\n",
      "Epoch 8/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2795 - val_loss: 0.2618\n",
      "Epoch 9/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2782 - val_loss: 0.2624\n",
      "Epoch 10/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2779 - val_loss: 0.2614\n",
      "Epoch 11/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2776 - val_loss: 0.2616\n",
      "Epoch 12/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2777 - val_loss: 0.2614\n",
      "Epoch 13/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2775 - val_loss: 0.2618\n",
      "Epoch 14/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2772 - val_loss: 0.2621\n",
      "Epoch 15/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2767 - val_loss: 0.2615\n",
      "Epoch 16/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2763 - val_loss: 0.2611\n",
      "Epoch 17/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2765 - val_loss: 0.2615\n",
      "Epoch 18/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2765 - val_loss: 0.2611\n",
      "Epoch 19/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2760 - val_loss: 0.2610\n",
      "Epoch 20/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2757 - val_loss: 0.2614\n",
      "Epoch 21/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2759 - val_loss: 0.2613\n",
      "Epoch 22/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2756 - val_loss: 0.2615\n",
      "Epoch 23/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2751 - val_loss: 0.2614\n",
      "Epoch 24/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2752 - val_loss: 0.2611\n",
      "Epoch 25/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2754 - val_loss: 0.2612\n",
      "Epoch 26/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2748 - val_loss: 0.2611\n",
      "Epoch 27/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2752 - val_loss: 0.2612\n",
      "Epoch 28/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2744 - val_loss: 0.2615\n",
      "Epoch 29/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2745 - val_loss: 0.2614\n",
      "Epoch 30/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2742 - val_loss: 0.2623\n",
      "Epoch 31/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2743 - val_loss: 0.2619\n",
      "Epoch 32/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2743 - val_loss: 0.2613\n",
      "Epoch 33/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2742 - val_loss: 0.2610\n",
      "Epoch 34/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2743 - val_loss: 0.2615\n",
      "Epoch 35/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2737 - val_loss: 0.2613\n",
      "Epoch 36/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2737 - val_loss: 0.2615\n",
      "Epoch 37/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2731 - val_loss: 0.2615\n",
      "Epoch 38/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2734 - val_loss: 0.2618\n",
      "Epoch 39/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2730 - val_loss: 0.2618\n",
      "Epoch 40/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2737 - val_loss: 0.2617\n",
      "Epoch 41/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2740 - val_loss: 0.2610\n",
      "Epoch 42/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2729 - val_loss: 0.2618\n",
      "Epoch 43/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2732 - val_loss: 0.2611\n",
      "Epoch 44/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2732 - val_loss: 0.2611\n",
      "Epoch 45/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2727 - val_loss: 0.2614\n",
      "Epoch 46/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2726 - val_loss: 0.2626\n",
      "Epoch 47/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2725 - val_loss: 0.2615\n",
      "Epoch 48/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2728 - val_loss: 0.2622\n",
      "Epoch 49/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2724 - val_loss: 0.2620\n",
      "Epoch 50/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2728 - val_loss: 0.2620\n",
      "Epoch 51/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2724 - val_loss: 0.2624\n",
      "Epoch 52/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2728 - val_loss: 0.2619\n",
      "Epoch 53/600\n",
      "618/618 [==============================] - 1s 2ms/step - loss: 0.2727 - val_loss: 0.2624\n",
      "Epoch 53: early stopping\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def f(mort_acc, total_acc):\n",
    "    if pd.isna(mort_acc):\n",
    "        return mean_values[total_acc]\n",
    "    else:\n",
    "        return mort_acc\n",
    "\n",
    "\n",
    "df = pd.read_csv('../DATA/lending_club_loan_two.csv')\n",
    "\n",
    "map_values = {'Fully Paid': 1, 'Charged Off': 0}\n",
    "df['loan_repaid'] = df['loan_status'].map(map_values)\n",
    "\n",
    "map_values = ['NONE', 'ANY']\n",
    "df['home_ownership'] = df['home_ownership'].replace(map_values, 'OTHER')\n",
    "\n",
    "df.drop(['emp_title', 'emp_length', 'title', 'grade', 'issue_d', 'loan_status'], axis=1, inplace=True)\n",
    "\n",
    "mean_values = df.groupby('total_acc').mean(numeric_only=True)['mort_acc']\n",
    "df['mort_acc'] = df.apply(lambda x: f(x.mort_acc, x.total_acc), axis=1)\n",
    "df['term'] = df.term.str.replace(r'[^0-9]', '', regex=True).astype('int')\n",
    "df['zip_code'] = df['address'].str[-5:]\n",
    "df['earliest_cr_line'] = df.earliest_cr_line.str.replace(r'[^0-9]', '', regex=True).astype('int')\n",
    "\n",
    "df.drop('address', axis=1, inplace=True)\n",
    "\n",
    "df.dropna(how='any', subset=['revol_util', 'pub_rec_bankruptcies'], inplace=True)\n",
    "\n",
    "dummies = pd.get_dummies(df[['zip_code', 'home_ownership', 'sub_grade', 'verification_status', 'application_type','initial_list_status','purpose']], drop_first=True)\n",
    "df = pd.concat([df.drop(['zip_code', 'home_ownership', 'sub_grade', 'verification_status', 'application_type','initial_list_status','purpose'], axis=1), dummies], axis=1)\n",
    "\n",
    "X = df.drop('loan_repaid', axis=1)\n",
    "y = df.loan_repaid\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# add the layers of neurons\n",
    "# add the layers of neurons\n",
    "model.add(Dense(78, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(39, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(19, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "# BINARY CLASIFICATION\n",
    "# hence the use of activation='sigmoid'\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "\n",
    "model.fit(x=X_train, \n",
    "        y=y_train, \n",
    "        epochs=600, \n",
    "        validation_data=(X_test, y_test), \n",
    "        callbacks=[tensorboard_callback, early_stop], \n",
    "        batch_size=512)\n",
    "\n",
    "model.save('code_along.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "95a63336fb5afd57d9efe9088177b2675a2da69331b02d1f884d9fdef354b05e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
